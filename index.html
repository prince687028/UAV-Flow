<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriately as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>OpenUAV</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">UAV-Flow Colosseo: A Real-World Benchmark for Flying-on-a-Word UAV Imitation Learning</h1>
            <div class="is-size-4 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Xiangyu Wang</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Donglin Yang</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Yue Liao</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="FOURTH AUTHOR PERSONAL LINK" target="_blank">Wenhao Zheng</a>,</span>
                <span class="author-block">
                  <a href="FIFTH AUTHOR PERSONAL LINK" target="_blank">Wenjun Wu</a>,</span>
                <span class="author-block">
                    <a href="SIXTH AUTHOR PERSONAL LINK" target="_blank">Bin Dai</a>,</span>
                <span class="author-block">
                  <a href="SEVENTH AUTHOR PERSONAL LINK" target="_blank">Hongsheng Li</a>,</span>
                <span class="author-block">
                  <a href="EIGHTH AUTHOR PERSONAL LINK" target="_blank">Si Liu</a><sup>†</sup></span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">Institute of Artificial Intelligence, Beihang University<br>MMLab, CUHK<br>Centre for Perceptual and Interactive Intelligence</span>
                <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution<br><sup>†</sup>Corresponding authors</small></span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Arxiv PDF link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2410.07087" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                    </a>
                  </span>

                  <!-- Supplementary PDF link -->
                  <span class="link-block">
                    <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/prince687028/TravelUAV" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                  </span>

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2410.07087" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

<!-- Teaser PNG image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/header2.png" alt="Header Image" style="width: 100%; height: auto;">
      <h2 class="subtitle has-text-justified">
        We propose a realistic UAV simulation platform and a novel UAV-Need-Help benchmark.
        The OpenUAV platform focuses on realistic UAV vision-language navigation tasks, integrating diverse environmental
        components, realistic flight simulations, and algorithmic support. 
        The UAV-Need-Help benchmark introduces an assistant-guided UAV object search task, where the UAV navigates to a target object
        using object descriptions, environmental information, and guidance from assistants.      
      </h2>
    </div>
  </div>
</section>
<!-- End teaser PNG image -->



  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Developing agents capable of navigating to a target location based on language instructions and visual information, known as vision-language navigation (VLN), has attracted widespread interest. Most research has focused on ground-based agents, while UAV-based VLN remains relatively underexplored. Recent efforts in UAV vision-language navigation predominantly adopt ground-based VLN settings, relying on predefined discrete action spaces and neglecting the inherent disparities in agent movement dynamics and the complexity of navigation tasks between ground and aerial environments. To address these disparities and challenges, we propose solutions from three perspectives: platform, benchmark, and methodology. To enable realistic UAV trajectory simulation in VLN tasks, we propose the OpenUAV platform, which features diverse environments, realistic flight control, and extensive algorithmic support. We further construct a target-oriented VLN dataset consisting of approximately 12k trajectories on this platform, serving as the first dataset specifically designed for realistic UAV VLN tasks. To tackle the challenges posed by complex aerial environments, we propose an assistant-guided UAV object search benchmark called UAV-Need-Help, which provides varying levels of guidance information to help UAVs better accomplish realistic VLN tasks. We also propose a UAV navigation LLM that, given multi-view images, task descriptions, and assistant instructions, leverages the multimodal understanding capabilities of the MLLM to jointly process visual and textual information, and performs hierarchical trajectory generation. The evaluation results of our method significantly outperform the baseline models, while there remains a considerable gap between our results and those achieved by human operators, underscoring the challenge presented by the UAV-Need-Help task.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <!-- Platform Scenarios Overview image -->
          <div class="carousel-image-wrapper">
            <img src="static/images/show.png" alt="Platform Scenarios Overview" class="carousel-image"/>
          </div>
          <h2 class="subtitle has-text-centered">
            Platform Scenarios Overview
          </h2>
        </div>
        <div class="item">
          <!-- Dataset Construction and Statistical Analysis image -->
          <div class="carousel-image-wrapper">
            <img src="static/images/dataset2.png" alt="Dataset Construction and Statistical Analysis" class="carousel-image"/>
          </div>
          <h2 class="subtitle has-text-centered">
            Dataset Construction and Statistical Analysis
          </h2>
        </div>
        <div class="item">
          <!-- Prompt Engineering in Description Collection image -->
          <div class="carousel-image-wrapper">
            <img src="static/images/prompt.png" alt="Prompt Engineering in Description Collection" class="carousel-image"/>
          </div>
          <h2 class="subtitle has-text-centered">
            Prompt Engineering in Description Collection
          </h2>
        </div>
        <div class="item">
          <!-- Overview of the Assistant Mechanism and UAV Navigation LLM Framework image -->
          <div class="carousel-image-wrapper">
            <img src="static/images/method2.png" alt="Overview of the Assistant Mechanism and UAV Navigation LLM Framework" class="carousel-image"/>
          </div>
          <h2 class="subtitle has-text-centered">
            Overview of the Assistant Mechanism and UAV Navigation LLM Framework
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->


  <!-- Paper poster -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Paper</h2>
        <iframe src="static/pdfs/OpenUAV.pdf" width="100%" height="550"></iframe>
      </div>
    </div>
  </section>
  <!-- End paper poster -->

  <!-- BibTeX citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{wang2024realisticuavvisionlanguagenavigation,
      title={Towards Realistic UAV Vision-Language Navigation: Platform, Benchmark, and Methodology},
      author={Xiangyu Wang and Donglin Yang and Ziqin Wang and Hohin Kwan and Jinyu Chen and Wenjun Wu and Hongsheng Li and Yue Liao and Si Liu},
      year={2024},
      eprint={2410.07087},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.07087},
}</code></pre>
  </div>
</section>
<!-- End BibTeX citation -->

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->
  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->
  <!-- End of Statcounter Code -->

</body>
</html>
